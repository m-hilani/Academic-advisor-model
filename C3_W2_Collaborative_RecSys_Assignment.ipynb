{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Packages <img align=\"left\" src=\"./images/film_strip_vertical.png\"     style=\" width:40px;   \" >\n",
    "We will use the now familiar NumPy and Tensorflow Packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "students_id column:\n",
      "       student_id  count_above_zero\n",
      "0            656                65\n",
      "1            657                65\n",
      "2            658                65\n",
      "3            659                65\n",
      "4            660                65\n",
      "...          ...               ...\n",
      "2423       35200                15\n",
      "2424       35224                21\n",
      "2425       35227                 8\n",
      "2426       35228                17\n",
      "2427       35260                22\n",
      "\n",
      "[2428 rows x 2 columns]\n",
      "\\courses :\n",
      "    course_id  count_above_zero\n",
      "0      Lvl 1                 0\n",
      "1      Lvl 2                 0\n",
      "2      Lvl 3                 0\n",
      "3      Lvl 4                 0\n",
      "4   PHAC 358              1723\n",
      "..       ...               ...\n",
      "70     RQUE2               397\n",
      "71     RQUE3               657\n",
      "72     RQUE4               128\n",
      "73     RQUE5              1637\n",
      "74     RQUE6               257\n",
      "\n",
      "[75 rows x 2 columns]\n",
      "[[ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 0.  0.  0. ...  0.  0.  0.]\n",
      " [79. 82. 62. ... 59.  0.  0.]\n",
      " [ 0.  0.  0. ...  0. 67.  0.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(r\"cf_train.csv\")\n",
    "# students_id = cf_train['student_id']\n",
    "# courses_id = cf_train.iloc[0]\n",
    "# Student IDs (first column)\n",
    "cf_test = pd.read_csv('cf_test.csv')\n",
    "\n",
    "student_ids = df.iloc[:, 0].tolist()\n",
    "\n",
    "# Course IDs (all columns except the first one)\n",
    "course_ids = df.columns[1:].tolist()\n",
    "# DataFrame for count of marks above zero for each course (column)\n",
    "marks_above_zero_per_course = (df.iloc[:, 1:] > 0).sum(axis=0).reset_index()\n",
    "marks_above_zero_per_course.columns = ['course_id', 'count_above_zero']\n",
    "\n",
    "# DataFrame for count of marks above zero for each student (row)\n",
    "marks_above_zero_per_student = (df.iloc[:, 1:] > 0).sum(axis=1).reset_index()\n",
    "marks_above_zero_per_student['student_id'] = df.iloc[:, 0]\n",
    "marks_above_zero_per_student = marks_above_zero_per_student[['student_id', 0]]\n",
    "marks_above_zero_per_student.columns = ['student_id', 'count_above_zero']\n",
    "\n",
    "# Marks only (drop student_id column)\n",
    "Y = df.iloc[:, 1:].values\n",
    "cf_test=df.iloc[:, 1:].values\n",
    "# Show the first column\n",
    "print(\"students_id column:\\n\", marks_above_zero_per_student)\n",
    "# Show the first row\n",
    "\n",
    "print(\"\\courses :\\n\", marks_above_zero_per_course)\n",
    "\n",
    "# Y = marks_matrix.to_numpy()\n",
    "Y=Y.T\n",
    "R = (Y != 0).astype(int)  # This would be correctprint(Y)\n",
    "print(Y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorized Implementation**\n",
    "\n",
    "It is important to create a vectorized implementation to compute $J$, since it will later be called many times during optimization. The linear algebra utilized is not the focus of this series, so the implementation is provided. If you are an expert in linear algebra, feel free to create your version without referencing the code below. \n",
    "\n",
    "Run the code below and verify that it produces the same results as the non-vectorized version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Vectorized for speed. Uses tensorflow operations to be compatible with custom training loop.\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    j = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y)*R\n",
    "    J = 0.5 * tf.reduce_sum(j**2) + (lambda_/2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalizeRatings(Y, R):\n",
    "    \"\"\"\n",
    "    Preprocess data by subtracting mean rating for every movie (every row).\n",
    "    Only include real ratings R(i,j)=1.\n",
    "    [Ynorm, Ymean] = normalizeRatings(Y, R) normalized Y so that each movie\n",
    "    has a rating of 0 on average. Unrated moves then have a mean rating (0)\n",
    "    Returns the mean rating in Ymean.\n",
    "    \"\"\"\n",
    "    Ymean = (np.sum(Y*R,axis=1)/(np.sum(R, axis=1)+1e-12)).reshape(-1,1)\n",
    "    Ynorm = Y - np.multiply(Ymean, R) \n",
    "    return(Ynorm, Ymean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Normalize the Dataset\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare to train the model. Initialize the parameters and select the Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#  Useful Values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 20\n",
    "\n",
    "# Set Initial Parameters (W, X), use tf.Variable to track these variables\n",
    "tf.random.set_seed(1234) # for consistent results\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features),dtype=tf.float64),  name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features),dtype=tf.float64),  name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),   dtype=tf.float64),  name='b')\n",
    "print(Y[0,0])\n",
    "\n",
    "# Instantiate an optimizer.\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now train the collaborative filtering model. This will learn the parameters $\\mathbf{X}$, $\\mathbf{W}$, and $\\mathbf{b}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operations involved in learning $w$, $b$, and $x$ simultaneously do not fall into the typical 'layers' offered in the TensorFlow neural network package.  Consequently, the flow used in Course 2: Model, Compile(), Fit(), Predict(), are not directly applicable. Instead, we can use a custom training loop.\n",
    "\n",
    "Recall from earlier labs the steps of gradient descent.\n",
    "- repeat until convergence:\n",
    "    - compute forward pass\n",
    "    - compute the derivatives of the loss relative to parameters\n",
    "    - update the parameters using the learning rate and the computed derivatives \n",
    "    \n",
    "TensorFlow has the marvelous capability of calculating the derivatives for you. This is shown below. Within the `tf.GradientTape()` section, operations on Tensorflow Variables are tracked. When `tape.gradient()` is later called, it will return the gradient of the loss relative to the tracked variables. The gradients can then be applied to the parameters using an optimizer. \n",
    "This is a very brief introduction to a useful feature of TensorFlow and other machine learning frameworks. Further information can be found by investigating \"custom training loops\" within the framework of interest.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_features 20 \n",
      " lamda 20 \n",
      "iterations 100\n",
      "Training loss at iteration 0: 9432754.2\n",
      "Training loss at iteration 20: 3687007.9\n",
      "Training loss at iteration 40: 2596534.1\n",
      "Training loss at iteration 60: 2173241.0\n",
      "Training loss at iteration 80: 2003865.2\n"
     ]
    }
   ],
   "source": [
    "iterations = 100\n",
    "lambda_ = 20\n",
    "print(\"num_features\",num_features , \n",
    "      \"\\n lamda\",lambda_,\n",
    "      \"\\niterations\",iterations)\n",
    "for iter in range(iterations):\n",
    "    # Use TensorFlow’s GradientTape\n",
    "    # to record the operations used to compute the cost \n",
    "    with tf.GradientTape() as tape:\n",
    "\n",
    "        # Compute the cost (forward pass included in cost)\n",
    "        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
    "\n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss\n",
    "    grads = tape.gradient( cost_value, [X,W,b] )\n",
    "\n",
    "    # Run one step of gradient descent by updating\n",
    "    # the value of the variables to minimize the loss.\n",
    "    optimizer.apply_gradients( zip(grads, [X,W,b]) )\n",
    "\n",
    "    # Log periodically.\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSzUL7eQodYS"
   },
   "source": [
    "<a name=\"6\"></a>\n",
    "## 6 - Recommendations\n",
    "Below, we compute the ratings for all the movies and users and display the movies that are recommended. These are based on the movies and ratings entered as `my_ratings[]` above. To predict the rating of movie $i$ for user $j$, you compute $\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}$. This can be computed for all ratings using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cost: 18.303188532365443\n"
     ]
    }
   ],
   "source": [
    "cost = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
    "R = tf.cast(R, tf.float64)\n",
    "\n",
    "average_cost = tf.reduce_sum(cost) / tf.reduce_sum(R)\n",
    "print(\"Average cost:\", average_cost.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (tf.linalg.matmul(X, tf.transpose(W)) + b )\n",
    "# print(Ymean)\n",
    "df = p.numpy() + Ymean\n",
    "p_df = pd.DataFrame(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 30)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>student_count_above_zero</th>\n",
       "      <th>course_id</th>\n",
       "      <th>course_count_above_zero</th>\n",
       "      <th>predicted_mark</th>\n",
       "      <th>mark</th>\n",
       "      <th>difference</th>\n",
       "      <th>semester_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>8671</td>\n",
       "      <td>50</td>\n",
       "      <td>RQUE3</td>\n",
       "      <td>657</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>23.0</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>7218</td>\n",
       "      <td>42</td>\n",
       "      <td>PHE1</td>\n",
       "      <td>1218</td>\n",
       "      <td>81.909740</td>\n",
       "      <td>9.0</td>\n",
       "      <td>72.909740</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>33129</td>\n",
       "      <td>12</td>\n",
       "      <td>PHE1</td>\n",
       "      <td>1218</td>\n",
       "      <td>83.033823</td>\n",
       "      <td>12.0</td>\n",
       "      <td>71.033823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>33684</td>\n",
       "      <td>16</td>\n",
       "      <td>PHBM 453</td>\n",
       "      <td>1743</td>\n",
       "      <td>82.417325</td>\n",
       "      <td>14.0</td>\n",
       "      <td>68.417325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>33684</td>\n",
       "      <td>16</td>\n",
       "      <td>PHR 209</td>\n",
       "      <td>1940</td>\n",
       "      <td>86.822341</td>\n",
       "      <td>19.0</td>\n",
       "      <td>67.822341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8173</th>\n",
       "      <td>11310</td>\n",
       "      <td>57</td>\n",
       "      <td>PHPT 931</td>\n",
       "      <td>1043</td>\n",
       "      <td>83.994411</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13156</th>\n",
       "      <td>24841</td>\n",
       "      <td>38</td>\n",
       "      <td>PHBM 552</td>\n",
       "      <td>1437</td>\n",
       "      <td>68.004787</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13343</th>\n",
       "      <td>24933</td>\n",
       "      <td>33</td>\n",
       "      <td>PHBM 654</td>\n",
       "      <td>1690</td>\n",
       "      <td>63.995395</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7425</th>\n",
       "      <td>21721</td>\n",
       "      <td>42</td>\n",
       "      <td>PHCC 728</td>\n",
       "      <td>1244</td>\n",
       "      <td>79.996898</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10780</th>\n",
       "      <td>28495</td>\n",
       "      <td>25</td>\n",
       "      <td>PHPP 642</td>\n",
       "      <td>1493</td>\n",
       "      <td>64.001775</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13665 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      student_id  student_count_above_zero course_id  course_count_above_zero  \\\n",
       "3505        8671                        50     RQUE3                      657   \n",
       "1956        7218                        42      PHE1                     1218   \n",
       "934        33129                        12      PHE1                     1218   \n",
       "4979       33684                        16  PHBM 453                     1743   \n",
       "1661       33684                        16   PHR 209                     1940   \n",
       "...          ...                       ...       ...                      ...   \n",
       "8173       11310                        57  PHPT 931                     1043   \n",
       "13156      24841                        38  PHBM 552                     1437   \n",
       "13343      24933                        33  PHBM 654                     1690   \n",
       "7425       21721                        42  PHCC 728                     1244   \n",
       "10780      28495                        25  PHPP 642                     1493   \n",
       "\n",
       "       predicted_mark  mark  difference  semester_number  \n",
       "3505       100.000000  23.0   77.000000                1  \n",
       "1956        81.909740   9.0   72.909740                1  \n",
       "934         83.033823  12.0   71.033823                1  \n",
       "4979        82.417325  14.0   68.417325                1  \n",
       "1661        86.822341  19.0   67.822341                1  \n",
       "...               ...   ...         ...              ...  \n",
       "8173        83.994411  84.0    0.005589                2  \n",
       "13156       68.004787  68.0    0.004787                2  \n",
       "13343       63.995395  64.0    0.004605                2  \n",
       "7425        79.996898  80.0    0.003102                1  \n",
       "10780       64.001775  64.0    0.001775                2  \n",
       "\n",
       "[13665 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of difference: 9.353514467064793\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build DataFrames\n",
    "df_true = pd.DataFrame(Y, index=course_ids, columns=student_ids)\n",
    "df_pred = pd.DataFrame(df, index=course_ids, columns=student_ids)\n",
    "\n",
    "cf_test = pd.read_csv('cf_test.csv')\n",
    "# Drop the first column from cf_test (assumes it's unnamed or index column)\n",
    "cf_test = cf_test.iloc[:, 1:]\n",
    "\n",
    "# Remove rows where the 'mark' column is zero (if column is named 'mark')\n",
    "if 'mark' in cf_test.columns:\n",
    "    cf_test = cf_test[cf_test['mark'] != 0]\n",
    "\n",
    "\n",
    "# print(cf_test.shape)\n",
    "\n",
    "# Give the index a name for easier melting\n",
    "df_true.index.name = \"course_id\"\n",
    "df_pred.index.name = \"course_id\"\n",
    "\n",
    "# Melt both into long format\n",
    "df_true_long = df_true.reset_index().melt(\n",
    "    id_vars=\"course_id\", var_name=\"student_id\", value_name=\"true_mark\"\n",
    ")\n",
    "\n",
    "df_pred_long = df_pred.reset_index().melt(\n",
    "    id_vars=\"course_id\", var_name=\"student_id\", value_name=\"predicted_mark\"\n",
    ")\n",
    "df_pred_long['predicted_mark'] = df_pred_long['predicted_mark'].clip(lower=0, upper=100)\n",
    "\n",
    "# Merge df_pred_long and cf_test on student_id and course_id to get predicted_mark and mark side by side\n",
    "merged_df = pd.merge(\n",
    "    cf_test,\n",
    "    df_pred_long,\n",
    "    on=[\"student_id\", \"course_id\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Merge in counts next to IDs\n",
    "student_counts = marks_above_zero_per_student.rename(columns={\"count_above_zero\": \"student_count\"})\n",
    "course_counts = marks_above_zero_per_course.rename(columns={\"count_above_zero\": \"course_count\"})\n",
    "merged_df = merged_df.merge(student_counts, on=\"student_id\", how=\"left\")\n",
    "merged_df = merged_df.merge(course_counts, on=\"course_id\", how=\"left\")\n",
    "\n",
    "# Create a new column 'difference' as the absolute difference between predicted_mark and mark\n",
    "merged_df['difference'] = (merged_df['predicted_mark'] - merged_df['mark']).abs()\n",
    "\n",
    "# Sort the DataFrame in descending order by the 'difference' column\n",
    "merged_df_sorted = merged_df.sort_values(by=['difference', 'predicted_mark'], ascending=[False, False])\n",
    "\n",
    "# Display the sorted DataFrame with counts next to IDs\n",
    "display(merged_df_sorted[[\n",
    "    \"student_id\",\n",
    "    \"student_count\",\n",
    "    \"course_id\",\n",
    "    \"course_count\",\n",
    "    \"predicted_mark\",\n",
    "    \"mark\",\n",
    "    \"difference\",\n",
    "    \"semester_number\"\n",
    "]])\n",
    "print(\"Mean of difference:\", merged_df_sorted[\"difference\"].mean())\n",
    "# display(df_pred_long)\n",
    "# display(cf_test)\n",
    "merged_df_sorted.to_csv('errors.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = merged_df_sorted[[\"student_id\", \"course_id\", \"predicted_mark\"]]\n",
    "# display(predictions)\n",
    "# Save DataFrame to CSV with MySQL-optimized format\n",
    "df_pred_long.to_csv(\n",
    "    'recommendation_results.csv',\n",
    "    index=False,\n",
    "    sep=',',\n",
    "    quoting=1,  # Quote all fields\n",
    "    escapechar='\\\\',\n",
    "    na_rep='NULL'\n",
    ")\n",
    "\n",
    "# Then use MySQL LOAD DATA INFILE command\n",
    "mysql_command = \"\"\"\n",
    "LOAD DATA INFILE 'C:/path/to/your/recommendation_results.csv'\n",
    "INTO TABLE recommendation_results\n",
    "FIELDS TERMINATED BY ','\n",
    "ENCLOSED BY '\"'\n",
    "LINES TERMINATED BY '\\\\n'\n",
    "IGNORE 1 ROWS;\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
